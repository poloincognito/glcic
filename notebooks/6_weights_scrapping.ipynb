{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "This notebooks adapts the weights scrapped online to my implementation architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from glic.networks.completion_network import CompletionNetwork\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my implementation CN architecure\n",
    "my_cn = CompletionNetwork()\n",
    "my_cn_state_dict = my_cn.state_dict()\n",
    "my_cn_shapes = OrderedDict([(k, v.shape) for k, v in my_cn_state_dict.items()])\n",
    "my_cn_shapes_serie = pd.Series(my_cn_shapes.values(),index = my_cn_shapes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # download the weight\n",
    "# trained_cn_weights_address = \"http://iizuka.cs.tsukuba.ac.jp/data/completionnet_places2.t7\"\n",
    "# import wget\n",
    "# wget.download(trained_cn_weights_address,\"../logs/scrapped_weights/trained_cn_weights.t7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weights were converted using https://github.com/clcarwin/convert_torch_to_pytorch  \n",
    "*The github project had to be forked to account for SpacialDilatedConvolution*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the converted weights\n",
    "scrapped_weights = torch.load(\"../logs/scrapped_weights/trained_cn_weights.pth\")\n",
    "scrapped_weights_shapes = OrderedDict([(k, v.shape) for k, v in scrapped_weights.items()])\n",
    "scrapped_weights_shapes_serie = pd.Series(scrapped_weights_shapes.values(),index = scrapped_weights_shapes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cn_net.0.0.weight                  (64, 3, 5, 5)\n",
       "cn_net.0.1.weight                          (64,)\n",
       "cn_net.0.1.bias                            (64,)\n",
       "cn_net.0.1.running_mean                    (64,)\n",
       "cn_net.0.1.running_var                     (64,)\n",
       "                                       ...      \n",
       "cn_net.15.1.bias                           (32,)\n",
       "cn_net.15.1.running_mean                   (32,)\n",
       "cn_net.15.1.running_var                    (32,)\n",
       "cn_net.15.1.num_batches_tracked               ()\n",
       "cn_net.16.0.weight                 (3, 32, 3, 3)\n",
       "Length: 97, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_cn_shapes_serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.weight                  (64, 4, 5, 5)\n",
       "0.bias                            (64,)\n",
       "1.weight                          (64,)\n",
       "1.bias                            (64,)\n",
       "1.running_mean                    (64,)\n",
       "                              ...      \n",
       "46.running_mean                   (32,)\n",
       "46.running_var                    (32,)\n",
       "46.num_batches_tracked               ()\n",
       "48.weight                 (3, 32, 3, 3)\n",
       "48.bias                            (3,)\n",
       "Length: 114, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrapped_weights_shapes_serie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer by layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cn_net.0.0.weight                 (64, 3, 5, 5)\n",
       "cn_net.0.1.weight                         (64,)\n",
       "cn_net.0.1.bias                           (64,)\n",
       "cn_net.0.1.running_mean                   (64,)\n",
       "cn_net.0.1.running_var                    (64,)\n",
       "cn_net.0.1.num_batches_tracked               ()\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_cn_shapes_serie.iloc[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.weight                 (64, 4, 5, 5)\n",
       "0.bias                           (64,)\n",
       "1.weight                         (64,)\n",
       "1.bias                           (64,)\n",
       "1.running_mean                   (64,)\n",
       "1.running_var                    (64,)\n",
       "1.num_batches_tracked               ()\n",
       "dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrapped_weights_shapes_serie.iloc[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the alpha bias\n",
    "conv2d = nn.Conv2d(4,64,kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
    "conv2d.parameters = scrapped_weights['0.weight']\n",
    "rgb_channels = torch.zeros((3,256,256))\n",
    "alpha_channel = torch.ones((1,256,256))\n",
    "alpha_image = torch.concatenate((rgb_channels,alpha_channel))\n",
    "alpha_bias = torch.mean(conv2d(alpha_image),dim=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set first layer\n",
    "my_cn_state_dict['cn_net.0.0.weight'] = scrapped_weights['0.weight'][:,:3,:,:]\n",
    "my_cn_state_dict['cn_net.0.1.weight'] = scrapped_weights['1.weight']\n",
    "my_cn_state_dict['cn_net.0.1.bias'] = scrapped_weights['0.bias']+scrapped_weights['1.bias']+alpha_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch norm layer\n",
    "shift = 1\n",
    "for idx in range(3,6):\n",
    "    my_cn_state_dict[my_cn_shapes_serie.index[idx]] = scrapped_weights[scrapped_weights_shapes_serie.index[idx+shift]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_layer(my_cn_layers_names,my_cn_state_dict,scrapped_weights_layers_names,scrapped_weights):\n",
    "    \"\"\"This function transfer the weights from scrapped weights to my implementation of CN.\n",
    "    \n",
    "    Args:\n",
    "        my_cn_layers_names (list): list of layers names to be transfered in my implementation of CN.\n",
    "        my_cn_state_dict (OrderedDict): my implementation of CN.\n",
    "        scrapped_weights_layers_names (list): list of layers names to be transfered in scrapped weights.\n",
    "        scrapped_weights (OrderedDict): scrapped weights.\n",
    "    \"\"\"\n",
    "\n",
    "    generic_map = {0:[0],\n",
    "                   1:[2],\n",
    "                   2:[1,3],\n",
    "                   3:[4],\n",
    "                   4:[5],\n",
    "                   5:[6],}\n",
    "    assert len(my_cn_layers_names) == 6\n",
    "    assert len(scrapped_weights_layers_names) == 7\n",
    "\n",
    "    for idx in range(6):\n",
    "        layer = my_cn_layers_names[idx]\n",
    "        my_cn_state_dict[layer] = torch.zeros(my_cn_state_dict[layer].shape)\n",
    "        for other_idx in generic_map[idx]:\n",
    "            other_layer = scrapped_weights_layers_names[other_idx]\n",
    "            my_cn_state_dict[layer] += scrapped_weights[other_layer]\n",
    "            print(f\"{other_layer} -> {layer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.weight -> cn_net.7.0.weight\n",
      "22.weight -> cn_net.7.1.weight\n",
      "21.bias -> cn_net.7.1.bias\n",
      "22.bias -> cn_net.7.1.bias\n",
      "22.running_mean -> cn_net.7.1.running_mean\n",
      "22.running_var -> cn_net.7.1.running_var\n",
      "22.num_batches_tracked -> cn_net.7.1.num_batches_tracked\n",
      "\n",
      "\n",
      "24.weight -> cn_net.8.0.weight\n",
      "25.weight -> cn_net.8.1.weight\n",
      "24.bias -> cn_net.8.1.bias\n",
      "25.bias -> cn_net.8.1.bias\n",
      "25.running_mean -> cn_net.8.1.running_mean\n",
      "25.running_var -> cn_net.8.1.running_var\n",
      "25.num_batches_tracked -> cn_net.8.1.num_batches_tracked\n",
      "\n",
      "\n",
      "27.weight -> cn_net.9.0.weight\n",
      "28.weight -> cn_net.9.1.weight\n",
      "27.bias -> cn_net.9.1.bias\n",
      "28.bias -> cn_net.9.1.bias\n",
      "28.running_mean -> cn_net.9.1.running_mean\n",
      "28.running_var -> cn_net.9.1.running_var\n",
      "28.num_batches_tracked -> cn_net.9.1.num_batches_tracked\n",
      "\n",
      "\n",
      "30.weight -> cn_net.10.0.weight\n",
      "31.weight -> cn_net.10.1.weight\n",
      "30.bias -> cn_net.10.1.bias\n",
      "31.bias -> cn_net.10.1.bias\n",
      "31.running_mean -> cn_net.10.1.running_mean\n",
      "31.running_var -> cn_net.10.1.running_var\n",
      "31.num_batches_tracked -> cn_net.10.1.num_batches_tracked\n",
      "\n",
      "\n",
      "33.weight -> cn_net.11.0.weight\n",
      "34.weight -> cn_net.11.1.weight\n",
      "33.bias -> cn_net.11.1.bias\n",
      "34.bias -> cn_net.11.1.bias\n",
      "34.running_mean -> cn_net.11.1.running_mean\n",
      "34.running_var -> cn_net.11.1.running_var\n",
      "34.num_batches_tracked -> cn_net.11.1.num_batches_tracked\n",
      "\n",
      "\n",
      "36.weight -> cn_net.12.0.weight\n",
      "37.weight -> cn_net.12.1.weight\n",
      "36.bias -> cn_net.12.1.bias\n",
      "37.bias -> cn_net.12.1.bias\n",
      "37.running_mean -> cn_net.12.1.running_mean\n",
      "37.running_var -> cn_net.12.1.running_var\n",
      "37.num_batches_tracked -> cn_net.12.1.num_batches_tracked\n",
      "\n",
      "\n",
      "39.weight -> cn_net.13.0.weight\n",
      "40.weight -> cn_net.13.1.weight\n",
      "39.bias -> cn_net.13.1.bias\n",
      "40.bias -> cn_net.13.1.bias\n",
      "40.running_mean -> cn_net.13.1.running_mean\n",
      "40.running_var -> cn_net.13.1.running_var\n",
      "40.num_batches_tracked -> cn_net.13.1.num_batches_tracked\n",
      "\n",
      "\n",
      "42.weight -> cn_net.14.0.weight\n",
      "43.weight -> cn_net.14.1.weight\n",
      "42.bias -> cn_net.14.1.bias\n",
      "43.bias -> cn_net.14.1.bias\n",
      "43.running_mean -> cn_net.14.1.running_mean\n",
      "43.running_var -> cn_net.14.1.running_var\n",
      "43.num_batches_tracked -> cn_net.14.1.num_batches_tracked\n",
      "\n",
      "\n",
      "45.weight -> cn_net.15.0.weight\n",
      "46.weight -> cn_net.15.1.weight\n",
      "45.bias -> cn_net.15.1.bias\n",
      "46.bias -> cn_net.15.1.bias\n",
      "46.running_mean -> cn_net.15.1.running_mean\n",
      "46.running_var -> cn_net.15.1.running_var\n",
      "46.num_batches_tracked -> cn_net.15.1.num_batches_tracked\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# other layers\n",
    "for idx in range(1,len(my_cn_shapes_serie)//6):\n",
    "    convert_layer(my_cn_shapes_serie.index[idx*6:idx*6+6],my_cn_state_dict,\n",
    "                  scrapped_weights_shapes_serie.index[idx*7:idx*7+7],scrapped_weights)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cn_net.15.1.weight                         (32,)\n",
       "cn_net.15.1.bias                           (32,)\n",
       "cn_net.15.1.running_mean                   (32,)\n",
       "cn_net.15.1.running_var                    (32,)\n",
       "cn_net.15.1.num_batches_tracked               ()\n",
       "cn_net.16.0.weight                 (3, 32, 3, 3)\n",
       "dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_cn_shapes_serie.iloc[-6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.weight                         (32,)\n",
       "46.bias                           (32,)\n",
       "46.running_mean                   (32,)\n",
       "46.running_var                    (32,)\n",
       "46.num_batches_tracked               ()\n",
       "48.weight                 (3, 32, 3, 3)\n",
       "48.bias                            (3,)\n",
       "dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrapped_weights_shapes_serie.iloc[-7:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
